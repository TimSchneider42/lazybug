@article{silver2016mastering,
    title = {Mastering the game of Go with deep neural networks and tree search},
    author = {Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
    journal = {nature},
    volume = {529},
    number = {7587},
    pages = {484-486},
    year = {2016},
    publisher = {Nature Publishing Group}
}
@online{Crazyara,
    author = {Johannes Czech, Moritz Willig, Alena Beyer},
    title = {CrazyAra - Deep Learning for Crazyhouse},
    note = {\url { https://github.com/QueensGambit/CrazyAra }},
    year = {(accessed on 12.06.2019)}
}
@online{freechess,
    title = {Free Internet Chess Server},
    note = {\url { https://www.freechess.org/ }},
    year = {(accessed on 13.06.2019)}
}
@online{bughousedatabase,
    title = {FICS Bughouse Database},
    note = {\url { https://www.bughouse-db.org/ }},
    year = {(accessed on 13.06.2019)}
}
@online{lichess,
    title = {Free Online Chess},
    note = {\url { https://lichess.org/ }},
    year = {(accessed on 13.06.2019)}
}
@online{chess,
    title = {Play Chess Online},
    note = {\url { https://www.chess.com/ }},
    year = {(accessed on 13.06.2019)}
}
@online{pychess,
    title = {Python Chess},
    note = {\url { https://github.com/niklasf/python-chess }},
    year = {(accessed on 13.06.2019)}
}
@online{pychesstim,
    title = {Fork of Python Chess},
    note = {\url { https://github.com/TimSchneider42/python-chess }},
    year = {(accessed on 13.06.2019)}
}

@online{bughouse_rules,
    title = {Laws of BUGHOUSE chess},
    note = {\url { http://bughousechess.wz.cz/CompleteBughouseChessRules.htm }},
    year = {(accessed on 15.06.2019)}
}

@online{sjeng,
    title = {Sjeng : a chess-and-variants playing program},
    note = {\url { https://sjeng.org/indexold.html }},
    year = {(accessed on 15.06.2019)}
}

@online{sunsetter,
    title = {Sunsetter},
    note = {\url { http://sunsetter.sourceforge.net/ }},
    year = {(accessed on 15.06.2019)}
}

@article{priorwork,
    author = {Potdar, Kedar and Pardawala, Taher and Pai, Chinmay},
    year = {2017},
    month = {10},
    pages = {7-9},
    title = {A Comparative Study of Categorical Variable Encoding Techniques for Neural Network Classifiers},
    volume = {175},
    journal = {International Journal of Computer Applications},
    doi = {10.5120/ijca2017915495}
}
@article{alphazero,
    author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
    title = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
    volume = {362},
    number = {6419},
    pages = {1140--1144},
    year = {2018},
    doi = {10.1126/science.aar6404},
    publisher = {American Association for the Advancement of Science},
    abstract = {Computers can beat humans at increasingly complex games, including chess and Go. However, these programs are typically constructed for a particular game, exploiting its properties, such as the symmetries of the board on which it is played. Silver et al. developed a program called AlphaZero, which taught itself to play Go, chess, and shogi (a Japanese version of chess) (see the Editorial, and the Perspective by Campbell). AlphaZero managed to beat state-of-the-art programs specializing in these three games. The ability of AlphaZero to adapt to various game rules is a notable step toward achieving a general game-playing system.Science, this issue p. 1140; see also pp. 1087 and 1118The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.},
    issn = {0036-8075},
    URL = {https://science.sciencemag.org/content/362/6419/1140},
    eprint = {https://science.sciencemag.org/content/362/6419/1140.full.pdf},
    journal = {Science}
}

@article{deepblue,
    title = {Deep blue},
    author = {Campbell, Murray and Hoane Jr, A Joseph and Hsu, Feng-hsiung},
    journal = {Artificial intelligence},
    volume = {134},
    number = {1-2},
    pages = {57--83},
    year = {2002},
    publisher = {Elsevier}
}

@article{alphago,
    title = {Mastering chess and shogi by self-play with a general reinforcement learning algorithm},
    author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
    journal = {arXiv preprint arXiv:1712.01815},
    year = {2017}
}

@article{checkers,
    title = {Checkers is solved},
    author = {Schaeffer, Jonathan and Burch, Neil and Bj{\"o}rnsson, Yngvi and Kishimoto, Akihiro and M{\"u}ller, Martin and Lake, Robert and Lu, Paul and Sutphen, Steve},
    journal = {science},
    volume = {317},
    number = {5844},
    pages = {1518--1522},
    year = {2007},
    publisher = {American Association for the Advancement of Science}
}

@online{keras,
    title = {Keras: The Python Deep Learning library},
    note = {\url { https://keras.io/ }},
    year = {(accessed on 15.09.2019)}
}

@online{tensorflow,
    title = {TensorFlow: An end-to-end open source machine learning platform},
    note = {\url { https://www.tensorflow.org/ }},
    year = {(accessed on 15.09.2019)}
}

@online{tinyChessServer,
    title = {tinyChessServer},
    note = {\url { https://github.com/MoritzWillig/tinyChessServer }},
    year = {(accessed on 15.09.2019)}
}

@online{code,
    title = {LazyBug - A Neural Bughouse Engine},
    note = {\url { https://github.com/TimSchneider42/lazybug }},
    year = {(accessed on 15.09.2019)}
}